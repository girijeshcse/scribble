<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Chapter 01 summary | Girijesh’s scribble and code</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Chapter 01 summary" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A synopsys of chapter 01 of book “Deep Learning with PyTorch”." />
<meta property="og:description" content="A synopsys of chapter 01 of book “Deep Learning with PyTorch”." />
<link rel="canonical" href="https://girijeshcse.github.io/scribble/markdown/2021/09/05/Deep-Learning-with-PyTorch-ch01.html" />
<meta property="og:url" content="https://girijeshcse.github.io/scribble/markdown/2021/09/05/Deep-Learning-with-PyTorch-ch01.html" />
<meta property="og:site_name" content="Girijesh’s scribble and code" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-09-05T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2021-09-05T00:00:00-05:00","url":"https://girijeshcse.github.io/scribble/markdown/2021/09/05/Deep-Learning-with-PyTorch-ch01.html","@type":"BlogPosting","headline":"Chapter 01 summary","dateModified":"2021-09-05T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://girijeshcse.github.io/scribble/markdown/2021/09/05/Deep-Learning-with-PyTorch-ch01.html"},"description":"A synopsys of chapter 01 of book “Deep Learning with PyTorch”.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/scribble/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://girijeshcse.github.io/scribble/feed.xml" title="Girijesh's scribble and code" /><link rel="shortcut icon" type="image/x-icon" href="/scribble/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/scribble/">Girijesh&#39;s scribble and code</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/scribble/about/">About Me</a><a class="page-link" href="/scribble/search/">Search</a><a class="page-link" href="/scribble/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Chapter 01 summary</h1><p class="page-description">A synopsys of chapter 01 of book "Deep Learning with PyTorch".</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-09-05T00:00:00-05:00" itemprop="datePublished">
        Sep 5, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/scribble/categories/#markdown">markdown</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#how-deep-learning-has-changed-the-way-we-look-">How deep learning has changed the way we look !</a></li>
<li class="toc-entry toc-h2"><a href="#why-pytorch">Why PyTorch</a>
<ul>
<li class="toc-entry toc-h3"><a href="#a-camparision-to-tensorflow">A camparision to TensorFlow</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#how-pytorch-supports-deep-learning-projects">How PyTorch supports deep learning projects.</a></li>
</ul><h2 id="how-deep-learning-has-changed-the-way-we-look-">
<a class="anchor" href="#how-deep-learning-has-changed-the-way-we-look-" aria-hidden="true"><span class="octicon octicon-link"></span></a>How deep learning has changed the way we look !</h2>
<p>This can be easily understood by this picture</p>

<p><img src="/scribble/images/dl1.JPG" alt="" title="Two approaches with and without Deep Learning"></p>

<ul>
  <li>We need a way to ingest whatever data we have at hand.</li>
  <li>We somehow need to define the deep learning machine.</li>
  <li>We must have an automated way, training, to obtain useful representations and make the machine produce desired outputs.</li>
</ul>

<h2 id="why-pytorch">
<a class="anchor" href="#why-pytorch" aria-hidden="true"><span class="octicon octicon-link"></span></a>Why PyTorch</h2>
<ul>
  <li>PyTorch gives us a data type, the Tensor, to hold numbers, vectors, matrices, or arrays in general. In addition, it provides functions for operating on them.</li>
  <li>It provides accelerated computation using graphical processing units (GPUs), often yielding speedups in the range of 50x over doing the same calculation on a CPU.</li>
  <li>PyTorch provides facilities that support numerical optimization on generic mathematical expressions, which deep learning uses for training.</li>
  <li>One of the motivations for this capability is to provide a reliable strategy for deploying models in production.</li>
  <li>Moving computations from the CPU to the GPU in PyTorch doesn’t require more than an additional function call or two. The second core thing that PyTorch provides is the ability of tensors to keep track of the operations performed on them and to analytically compute derivatives of an output of a computation with respect to any of its inputs. This is used for numerical optimization, and it is provided natively by tensors by virtue of dispatching through PyTorch’s autograd engine under the hood.</li>
  <li>The core PyTorch modules for building neural networks are located in torch.nn, which provides common neural network layers and other architectural components. Fully connected layers, convolutional layers, activation functions, and loss functions can all be found here.</li>
</ul>

<h3 id="a-camparision-to-tensorflow">
<a class="anchor" href="#a-camparision-to-tensorflow" aria-hidden="true"><span class="octicon octicon-link"></span></a>A camparision to TensorFlow</h3>
<p>TensorFlow has a robust pipeline to production, an extensive industry-wide community,
and massive mindshare. PyTorch has made huge inroads with the research and
teaching communities, thanks to its ease of use, and has picked up momentum since,
as researchers and graduates train students and move to industry.</p>

<h2 id="how-pytorch-supports-deep-learning-projects">
<a class="anchor" href="#how-pytorch-supports-deep-learning-projects" aria-hidden="true"><span class="octicon octicon-link"></span></a>How PyTorch supports deep learning projects.</h2>
<ul>
  <li>First we need to physically get the data, most often from some sort of storage as the data source. Then we need to convert each sample from our data into a something PyTorch can actually handle: tensors</li>
  <li>This bridge between our custom data (in whatever format it might be) and a standardized PyTorch tensor is the Dataset class PyTorch provides in torch.utils.data.</li>
  <li>we will need multiple processes to load our data, in order to assemble them into batches: tensors that encompass several samples. This is rather elaborate; but as it is also relatively generic, PyTorch readily provides all that magic in the DataLoader class. Its instances can spawn child processes to load data from a dataset in the background so that it’s ready and waiting for the training loop as soon as the loop can use it.</li>
  <li>At each step in the training loop, we evaluate our model on the samples we got from the data loader. We then compare the outputs of our model to the desired  output (the targets) using some criterion or loss function.</li>
</ul>

<p><img src="/scribble/images/dl2.JPG" alt=" " title="PyTotch deep learning stages"></p>

<ul>
  <li>The training loop might be the most unexciting yet most time-consuming part of a deep learning project. At the end of it, we are rewarded with a model whose parameters have been optimized on our task: the trained model depicted to the right of the training loop in the figure.</li>
  <li>PyTorch defaults to an immediate execution model (eager mode). Whenever an instruction involving PyTorch is executed by the Python interpreter, the corresponding operation is immediately carried out by the underlying C++ or CUDA implementation.</li>
</ul>


  </div><a class="u-url" href="/scribble/markdown/2021/09/05/Deep-Learning-with-PyTorch-ch01.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/scribble/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/scribble/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/scribble/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>A place to explore and rewrite my technical voyage.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/girijeshcse" title="girijeshcse"><svg class="svg-icon grey"><use xlink:href="/scribble/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/girijesh_" title="girijesh_"><svg class="svg-icon grey"><use xlink:href="/scribble/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
